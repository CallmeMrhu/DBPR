1、MovieLen数据集中的数据，每个用户的打分时间过于集中，时间跨度不够大。
    如果使用timestamp进行划分会导致打分较早的用户在测试集中没有数据；
    而打分较迟的用户会在训练集中没有数据，出现冷启动问题。

2、使用Last-FM数据集，按照timestamp进行划分，不能按照之前处理MovieLen时直接取用户的前80%数据

3、在计算t时间段时，可以直接使用timestamp来进行划分
    其中划分方式可以采用pandas中的dataframe中对某一列进行过滤的方法，
        对下界timestamp加上时间间隔所转换成的timestamp值，则可以得到上界，
            于是就可以直接过滤得到所需要的数据，同理对各个时间段都可以采用相同的方法进行划分。

user_000001	2009-04-10T16:05:12Z	463a94f1-2713-40b1-9c88-dcc9c0170cae	Minus 8	f78c95a8-9256-4757-9a9f-213df5c6854e	Cold Fusion

user_000001                                 1
2009-04-10T16:05:12Z                        timestamp
f78c95a8-9256-4757-9a9f-213df5c6854e        traid

对时间序列的操作：
1、过滤掉user、item、timestamp为空的行
1、对过滤空行的数据集继续进行清理，其中将user_id用连续自然数表示，在music_id也用连续自然数表示，timestamp转换为用秒表示
2、先按照时间划分得到多个dataframe，当然不同的时间划分得到的dataframe的时间个数也不一样
3、第一个时间段t计算梯度时，上一个时间段的值可以用初始化的值表示，初始化为多少得思考
4、非第一个时间段t计算提督，需要用到上一个时间段的值时，则说明上一个时间段的Pu和Qi矩阵得单独保存一份。


t=0 419805
t=1 955470
t=2 1985952
t=3 2483596
t=4 2606951
t=5 2666297
sum 11118071
time interval : 1.5 years
validation/test : 1.5 years

Standard-BPR: step time
0 step :1411
1 step :1386
2 step :1496
3 step :1469
4 step :2639
5 step :1682
6 step :1378
7 step :1407
8 step :1413
9 step :1439
10 step :1449
11 step :1451
12 step :1423


DBPR: step time
0 step :2702
1 step :2871
2 step :4032
3 step :2941
4 step :2782
5 step :2855
6 step :5860

2018.1.12
根据之前讨论，接下来的任务是
1、更改时间间隔（interval）
2、使用别的度量标准 RMSE，可以使用已经训练好的矩阵来计算

2018.1.13
使用最好情况的userMat和itemMat来计算其他的度量标准
DBPR选择之前AUC最好情况时的userMat30.txt和itemMat30.txt
BPR选择之前AUC最好情况时的userMat48.txt和itemMat48.txt

2018.1.14
计算得到多种时间序列划分，然后分别计算得到AUC、Recall、Precision
2018.1.15
使用新的数据集进行训练、另外思考一下是否可以使用新的度量标准、以及对比实验还是不够完善

dataset:FineFoods
DPF复现

2018.1.20
1、对Epinions和FineFoods已经划分好的数据进行实验
2、对dPF进行复现，直接跑C++程序
3、计算recall和precision

2018.1.23
1、对dPF进行复现
2、继续寻找合适的数据集进行训练

dat -n 992 -m 983
data_Epinions -n 1461 -m 17765
data_FineFoods -n 1892 -m 19489
data_Netflix -n 23928 -m 17771

2018.4.14
在对数据进行划分时，使用drop([row])来删除不符合条件的行数会导致内存大大增加，几十个G的内存量，最后会被系统强制退出
最后是用来isin()的方法，即先对所有的睡觉进行判断，是否符合条件，符合为True，不符合为False，得到一个集合M
然后再使用df[M]来进行筛选，返回符合条件的行的dataframe。

对csv中浮点数转换为整数，即xxx.0的转换为xxx，遇到了一些麻烦，开始是想将数字转换为int，然后在转换为str型，发现执行起来特别慢；
于是直接对文件进行操作，读取文件，然后每行用line.strip('\n').split('\t')[0]/[1]...来进行获取，
对于xxx.0可以用(xxx.0).split('.')[0]来获取xxx部分，最后写入文件即可；且以下操作效果更好，既不会占用太多的内存，又可以提高执行速度
                    f = open(filepath)
                    while 1:
                        lines = f.readlines(10000)
                        if not line:
                            break
                        for line in lines:
                            #operation
2018.4.28
对几个数据集都训练完毕，但是git错误，误删除
对第一个时间段进行增加，来训练看是否有提高

2018.4.30
MovieLen
max_Timestamp: 1427784002
min_Timestamp 824835410
usernumber: 10702
itemnumber: 26231

movielen的validation和test中user的数量为1900左右
netflix的validation和test中user的数量为23420左右

main_running_standard.py 中 0.02-0.02-0.02的参数还没有训练

2018.5.1
目前来说MovieLen数据集在0.02-0.1-0.02和0.02-0.02-0.02上的结果还可以，但是AUC还未收敛，

2018.5.4
先写完论文，如果时间来得及再加一个timeSVD++